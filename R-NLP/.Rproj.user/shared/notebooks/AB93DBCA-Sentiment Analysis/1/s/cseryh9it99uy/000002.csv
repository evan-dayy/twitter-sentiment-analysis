"0","## nrc"
"0","nrc<- get_sentiments(""nrc"")"
"1","Do you want to download:
"
"1"," "
"1","Name:"
"1"," "
"1","NRC Word-Emotion Association Lexicon"
"1"," "
"1","
"
"1"," "
"1","URL:"
"1"," "
"1","http://saifmohammad.com/WebPages/lexicons.html"
"1"," "
"1","
"
"1"," "
"1","License:"
"1"," "
"1","License required for commercial use. Please contact Saif M. Mohammad (saif.mohammad@nrc-cnrc.gc.ca)."
"1"," "
"1","
"
"1"," "
"1","Size:"
"1"," "
"1","22.8 MB (cleaned 424 KB)"
"1"," "
"1","
"
"1"," "
"1","Download mechanism:"
"1"," "
"1","http"
"1"," "
"1","
"
"1"," "
"1","Citation info:

This dataset was published in Saif M. Mohammad and Peter Turney. (2013), ``Crowdsourcing a Word-Emotion Association Lexicon.'' Computational Intelligence, 29(3): 436-465.

article{mohammad13,
author = {Mohammad, Saif M. and Turney, Peter D.},
title = {Crowdsourcing a Word-Emotion Association Lexicon},
journal = {Computational Intelligence},
volume = {29},
number = {3},
pages = {436-465},
doi = {10.1111/j.1467-8640.2012.00460.x},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1467-8640.2012.00460.x},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1467-8640.2012.00460.x},
year = {2013}
}
If you use this lexicon, then please cite it."
"1"," "
"1","
"
"1",""
"1","
"
"1","1: Yes"
"1","
"
"1","2: No"
"1","
"
"1",""
"1","
"
"0","1"
"2","trying URL 'http://saifmohammad.com/WebDocs/NRC-Emotion-Lexicon.zip'
"
"2","Content type 'application/zip'"
"2"," length 24199292 bytes (23.1 MB)
"
"2","="
"2","="
"2","="
"2","="
"2","="
"2","="
"2","="
"2","="
"2","="
"2","="
"2","="
"2","="
"2","="
"2","="
"2","="
"2","="
"2","="
"2","="
"2","="
"2","="
"2","="
"2","="
"2","="
"2","="
"2","="
"2","="
"2","="
"2","="
"2","="
"2","="
"2","="
"2","="
"2","="
"2","="
"2","="
"2","="
"2","="
"2","="
"2","="
"2","="
"2","="
"2","="
"2","="
"2","="
"2","="
"2","="
"2","="
"2","="
"2","="
"2","="
"2","
"
"2","downloaded 23.1 MB

"
"0","sentment_nrc = tidy_books %>%"
"0","        inner_join(nrc) %>%"
"0","        count(date, time, word, sentiment) %>%"
"0","        spread(sentiment, n, fill = 0) %>%"
"0","        select(-word)%>%"
"0","        group_by(date, time) %>%"
"0","        summarise_all(sum)"
"0",""
"0",""
