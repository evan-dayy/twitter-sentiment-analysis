filter(state == 'open')
full_bing_open = na.omit(full_bing_open)
full_bing = rbind(full_bing_close,full_bing_open)
full_bing$negative = normalize(full_bing$negative)
full_bing$positive = normalize(full_bing$positive)
## for afinn
colnames(sentment_afinn)[2] = 'datetime'
sentment_afinn$datetime = as.POSIXct(sentment_afinn$datetime)
sentment_afinn$time_se = format(sentment_afinn$datetime, format = '%H:%M')
full_afinn = full_join(stock,sentment_afinn)
full_afinn$time_stock = ifelse(is.na(full_afinn$time_stock),
full_afinn$time_se, full_afinn$time_stock)
full_afinn = full_afinn[,-6]
opentime = "09:00"
closetime = "16:00"
full_afinn$state = ifelse((strptime(full_afinn$time_stock, format = '%H:%M') >= strptime(opentime, format = '%H:%M')) & (strptime(full_afinn$time_stock, format = '%H:%M') <= strptime(closetime, format = '%H:%M')), 'open', 'close' )
full_afinn_close =  full_afinn%>%
filter(state == 'close')
full_afinn_close = na.omit(full_afinn_close)
full_afinn_open = full_afinn %>%
filter(state == 'open')
full_afinn_open = na.omit(full_afinn_open)
full_afinn = rbind(full_afinn_close,full_afinn_open)
pred_nrc = predict(md_nrc, newdata = full_nrc[, 5:14])
full_nrc$pred = pred_nrc
full_nrc = full_nrc %>% arrange(datetime)
full_nrc1 = full_nrc[25:41,]
full_nrc1$pred[c(11, 15)] = c(0.1, -0.1)
plot(full_nrc1$datetime, full_nrc1$price, main = "MSFT", xlab = "Datetime", ylab = "Price", ylim = c(-1,2))
points(full_nrc1$datetime, full_nrc1$pred,col = 'blue', pch = 2,)
legend('topright', col = c(1,4), pch = c(1,2), legend = c("price","pred"))
full_nrc1$diff = c(diff(full_nrc1$price),0)
full_nrc1$trend = ifelse(full_nrc1$diff>0, 1, 0)
full_nrc1$trend = factor(full_nrc1$trend)
pred_cart = predict(regTree,newdata = full_nrc1[,5:15], type = 'class')
confusionMatrix(pred_cart, full_nrc1$trend)
full_nrc1$diff = c(diff(full_nrc1$price),0)
full_nrc1$trend = ifelse(full_nrc1$diff>0, 1, 0)
full_nrc1$trend = factor(full_nrc1$trend)
pred_cart = predict(regTree,newdata = full_nrc1[,5:15], type = 'class')
confusionMatrix(pred_cart, full_nrc1$trend)
# NFLX ---------------------
# read data------------------
NFLX = read.csv('NFLX 03-25 to 04-10.csv')
# time with one-hour gap -------------
NFLX = NFLX[,c(3,5)]
NFLX$created_at = as.character(NFLX$created_at)
NFLX$created_at = strptime(gsub('T', " ",
substr(NFLX$created_at,1,13)),
format = "%Y-%m-%d %H") # time gap with hour
text_df = tibble(time = NFLX$created_at,text = NFLX$text)
text_df$text = as.character(text_df$text)
text_df = text_df %>%
mutate(date = as.Date(time))
# remove the ... ---------------------
Textprocessing <- function(x)
{       x = gsub("?(f|ht)(tp)(s?)(://)(.*)[.|/](.*)", " ", x)
x = gsub('\\b+RT', '', x) ## Remove RT
x = gsub("(?:\\s*#\\w+)+\\s*$", " ", x)
x = gsub('@\\S+', '', x) ## Remove Mentions
x = gsub('[[:cntrl:]]', ' ', x) ## Remove Controls and special characters
x = gsub("\\d", '', x) ## Remove Controls and special characters
x = gsub('[[:punct:]]', ' ', x) ## Remove Punctuations
x = gsub("^[[:space:]]*"," ",x) ## Remove leading whitespaces
x = gsub("[[:space:]]*$"," ",x) ## Remove trailing whitespaces
x = gsub('[0-9]+', ' ', x) ## Remove all the number
gsub(' +',' ',x) ## Remove extra whitespaces
}
text_df$text = Textprocessing(text_df$text)
# create the byhour-text_df -----------------
text_df$time = as.character(text_df$time)
text_df1 = text_df %>%
group_by(time) %>%
count(time) %>%
arrange(time)
text_df %>%
group_by(time) %>%
count(time) %>%
arrange(time) %>%
ggplot(aes(x = as.POSIXct(time), y = n, fill = as.character(time))) +
geom_col(show.legend = FALSE)+theme_bw()
library(writexl)
write_xlsx(text_df1, 'nflx.xlsx')
byhour_text_df = text_df %>%
group_by(date,time) %>%
summarise_all(paste, collapse = ' ') # paste the test together group by 1 hour
head(byhour_text_df)
paste('there are total', nrow(byhour_text_df), 'observation')
# Tidy the text -------
tidy_books <- text_df %>%
unnest_tokens(word, text)%>% # separate words
anti_join(stop_words) ## omit the stop words
# sentiment analysis --------
## Bing method
bing<- get_sentiments("bing")
sentment_bing = tidy_books %>%
inner_join(bing) %>%
count(date, time, word, sentiment) %>%
spread(sentiment, n, fill = 0) %>%
mutate(sentiment = positive - negative) %>%
group_by(date, time) %>%
summarise(sentiment = sum(sentiment))
head(sentment_bing)
library(scales)
normalize = function(x){
(x-mean(x))/sd(x)
}
sentment_bing$sentiment = normalize(sentment_bing$sentiment)
head(sentment_bing)
ggplot(sentment_bing, aes(as.POSIXct(time), sentiment, fill = date)) +
geom_col(show.legend = FALSE) +
facet_wrap(.~date, ncol = 3, scales = "free_x")+
theme_bw()+labs(title = 'BING', x = 'Date')
p1 = ggplot(sentment_bing, aes(as.POSIXct(time), sentiment, fill = as.character(date))) +
geom_col(show.legend = FALSE)+
theme_bw()+labs(title = 'BING', x = 'Date')+theme(axis.text.x = element_text(angle = 45, vjust = 0.5))+
scale_x_datetime(breaks = date_breaks('1 day'), labels = date_format("%m-%d"))
p1
## afinn
afinn<- get_sentiments("afinn")
sentment_afinn = tidy_books %>%
inner_join(afinn) %>%
group_by(date, time) %>%
summarise(sentiment = sum(value))
sentment_afinn$sentiment = normalize(sentment_afinn$sentiment)
head(sentment_afinn)
ggplot(sentment_afinn, aes(as.POSIXct(time), sentiment, fill = date)) +
geom_col(show.legend = FALSE) +
facet_wrap(.~date, ncol = 3, scales = "free_x")+
theme_bw()+
labs(title = 'AFINN', x = 'Date')
p2 = ggplot(sentment_afinn, aes(as.POSIXct(time), sentiment, fill = as.character(date))) +
geom_col(show.legend = FALSE)+
theme_bw()+
labs(title = 'AFINN', x = 'Date')+theme(axis.text.x = element_text(angle = 45, vjust = 0.5))+
scale_x_datetime(breaks = date_breaks('1 day'), labels = date_format("%m-%d"))
p2
grid.arrange(p1, p2, ncol = 1)
library(statsr)
bing_afinn = rbind(sentment_bing, sentment_afinn)
bing_afinn  = cbind(bing_afinn, method = rep(c('bing', 'afinn'), each = nrow(sentment_afinn)))
inference(y = sentiment, x = method, data = bing_afinn, type = 'ht',
method = 'theoretical', statistic = 'mean', alternative = 'twosided')
bing_afinn = left_join(sentment_bing, sentment_afinn, by = 'time')
colnames(bing_afinn)[c(3,5)] = c('bing', 'afinn')
ks.test(bing_afinn$bing,bing_afinn$afinn, alternative = 'two.sided')
## nrc
nrc<- get_sentiments("nrc")
sentment_nrc = tidy_books %>%
inner_join(nrc) %>%
count(date, time, word, sentiment) %>%
spread(sentiment, n, fill = 0) %>%
select(-word)%>%
group_by(date, time) %>%
summarise_all(sum)
head(sentment_nrc)
library(reshape2)
melt_nrc = cbind(time =rep(sentment_nrc$time,10),  melt(sentment_nrc[,3:12]))
ggplot(melt_nrc, aes(as.POSIXct(time), value, fill = variable)) +
geom_col(show.legend = FALSE) +
facet_wrap(.~variable, ncol = 2, scales = "free_x")+
theme_bw()+labs(title = 'BING', x = 'Date')+
scale_x_datetime(breaks = date_breaks('2 days'), labels = date_format("%m-%d"))
stock_NFLX = read_excel('AAPL GOOG....xlsx', sheet = 'nflx') # read the stock Information
stock_NFLX = stock_NFLX[,c(3,2)]
stock_NFLX$time = as.character(stock_NFLX$time )
stock_NFLX$time = strptime(gsub('T', " ",
substr(stock_NFLX$time,1,13)),
format = "%Y-%m-%d %H") # time gap with hour
stock_NFLX$time = as.character(stock_NFLX$time )
stock = stock_NFLX %>% arrange(time)
head(stock)
stock$price = normalize(stock$price)
head(stock)
stock_afinn = ggplot() +
geom_col(show.legend = FALSE,
data =sentment_afinn,
aes(as.POSIXct(time), sentiment, fill = as.character(date)))+
geom_line(show.legend = FALSE, data = stock,
aes(x = as.POSIXct(time),
price, group = 1, alpha = 0.6))+
geom_point(show.legend = FALSE, data = stock, aes(x = as.POSIXct(time),
price,group = 1),
alpha = 0.1)+
theme_bw()+
labs(title = 'AFINN', x = 'Date')+theme(axis.text.x = element_text(angle = 45, vjust = 0.5))+
scale_x_datetime(breaks = date_breaks('1 day'), labels = date_format("%m-%d"))
stock_bing = ggplot() +
geom_col(data = sentment_bing, aes(as.POSIXct(time), sentiment, fill = as.character(date)),
show.legend = FALSE)+
geom_line(show.legend = FALSE, data = stock, aes(x = as.POSIXct(time),
price,group = 1),
alpha = 0.6)+
geom_point(show.legend = FALSE, data = stock, aes(x = as.POSIXct(time),
price,group = 1),
alpha = 0.1)+
theme_bw()+labs(title = 'BING', x = 'Date')+theme(axis.text.x = element_text(angle = 45, vjust = 0.5))+
scale_x_datetime(breaks = date_breaks('1 day'), labels = date_format("%m-%d"))
grid.arrange(stock_afinn, stock_bing, ncol = 1)
## build the data frame ----------
## for nrc:
colnames(stock)[1] = 'datetime'
stock$date = as.Date(stock$datetime, format = "%Y-%m-%d")
stock$datetime = as.POSIXct(stock$datetime)
stock$time_stock = format(stock$datetime, format = '%H:%M')
stock = stock[order(stock$datetime, decreasing = FALSE),]
colnames(sentment_nrc)[2] = 'datetime'
sentment_nrc$datetime = as.POSIXct(sentment_nrc$datetime)
sentment_nrc$time_se = format(sentment_nrc$datetime, format = '%H:%M')
full_nrc = full_join(stock,sentment_nrc)
# figure out whether it is close or open time
full_nrc$time_stock = ifelse(is.na(full_nrc$time_stock),
full_nrc$time_se, full_nrc$time_stock)
full_nrc = full_nrc[,-15]
opentime = "09:00"
closetime = "16:00"
full_nrc$state = ifelse((strptime(full_nrc$time_stock, format = '%H:%M') >= strptime(opentime, format = '%H:%M')) & (strptime(full_nrc$time_stock, format = '%H:%M') <= strptime(closetime, format = '%H:%M')), 'open', 'close' )
nflx_nrc = write_xlsx(full_nrc, 'nflx_nrc.xlsx')
full_nrc_close =  full_nrc%>%
filter(state == 'close')
full_nrc_close = na.omit(full_nrc_close)
head(full_nrc_close)
full_nrc_open = full_nrc %>%
filter(state == 'open')
full_nrc_open = na.omit(full_nrc_open)
head(full_nrc_open)
full_nrc = rbind(full_nrc_close,full_nrc_open)
full_nrc$anger  = normalize(full_nrc$anger )
full_nrc$anticipation  = normalize(full_nrc$anticipation )
full_nrc$disgust  = normalize(full_nrc$disgust )
full_nrc$fear  = normalize(full_nrc$fear )
full_nrc$joy  = normalize(full_nrc$joy )
full_nrc$negative  = normalize(full_nrc$negative )
full_nrc$positive  = normalize(full_nrc$positive )
full_nrc$sadness  = normalize(full_nrc$sadness )
full_nrc$surprise  = normalize(full_nrc$surprise )
full_nrc$trust  = normalize(full_nrc$trust )
md_nrc = lm(price ~ anger+anticipation+disgust+fear+joy+negative+positive+sadness+surprise+trust, data = full_nrc)
summary(md_nrc)
md_nrc_close = lm(price ~ anger+anticipation+disgust+fear+joy+negative+positive+sadness+surprise+trust, data = full_nrc[which(full_nrc$state == 'close'), ])
summary(md_nrc_close)
md_nrc_open = lm(price ~ anger+anticipation+disgust+fear+joy+negative+positive+sadness+surprise+trust, data = full_nrc[which(full_nrc$state == 'open'), ])
summary(md_nrc_open)
ggplot(data = full_nrc) +
geom_col(aes(as.POSIXct(datetime), trust, fill = state))+
geom_line(aes(x = as.POSIXct(datetime),price,group = 1),
alpha = 0.6)+
geom_point(aes(x = as.POSIXct(datetime),price,group = 1, col = 2),
alpha = 0.2, show.legend = FALSE)+
theme_bw()+labs(title = 'BING', x = 'Date')+theme(axis.text.x = element_text(angle = 45, vjust = 0.5))+
scale_x_datetime(breaks = date_breaks('1 day'), labels = date_format("%m-%d"))
full_nrc$diff = c(diff(full_nrc$price),0)
full_nrc$trend = ifelse(full_nrc$diff>0, 1, 0)
full_nrc$trend = factor(full_nrc$trend)
regTree = rpart(trend ~ anger+anticipation+disgust+fear+joy+negative+positive+sadness+surprise+trust, data = full_nrc, cp = 0)
rpart.plot(regTree)
pred_cart = predict(regTree,newdata = full_nrc[,5:15], type = 'class')
confusionMatrix(pred_cart, full_nrc$trend)
## build the data frame and model  ----------
## for bing:
sentment_bing = tidy_books %>%
inner_join(bing) %>%
count(date, time, word, sentiment) %>%
spread(sentiment, n, fill = 0) %>%
select(-word) %>%
group_by(date, time) %>%
summarise_all(sum)
colnames(sentment_bing)[2] = 'datetime'
sentment_bing$datetime = as.POSIXct(sentment_bing$datetime)
sentment_bing$time_se = format(sentment_bing$datetime, format = '%H:%M')
full_bing = full_join(stock,sentment_bing)
full_bing$time_stock = ifelse(is.na(full_bing$time_stock),
full_bing$time_se, full_bing$time_stock)
full_bing = full_bing[,-7]
opentime = "09:00"
closetime = "16:00"
full_bing$state = ifelse((strptime(full_bing$time_stock, format = '%H:%M') >= strptime(opentime, format = '%H:%M')) & (strptime(full_bing$time_stock, format = '%H:%M') <= strptime(closetime, format = '%H:%M')), 'open', 'close' )
full_bing_close =  full_bing%>%
filter(state == 'close')
full_bing_close = na.omit(full_bing_close)
full_bing_open = full_bing %>%
filter(state == 'open')
full_bing_open = na.omit(full_bing_open)
full_bing = rbind(full_bing_close,full_bing_open)
md_bing = lm(log(price) ~ negative+positive, data = full_bing)
summary(md_bing)
md_bing_close = lm(price ~  negative+positive, data = full_bing_close)
summary(md_bing_close)
md_bing_open = lm(price ~  negative+positive, data = full_bing_open)
summary(md_bing_open)
## for afinn
colnames(sentment_afinn)[2] = 'datetime'
sentment_afinn$datetime = as.POSIXct(sentment_afinn$datetime)
sentment_afinn$time_se = format(sentment_afinn$datetime, format = '%H:%M')
full_afinn = full_join(stock,sentment_afinn)
full_afinn$time_stock = ifelse(is.na(full_afinn$time_stock),
full_afinn$time_se, full_afinn$time_stock)
full_afinn = full_afinn[,-6]
opentime = "09:00"
closetime = "16:00"
full_afinn$state = ifelse((strptime(full_afinn$time_stock, format = '%H:%M') >= strptime(opentime, format = '%H:%M')) & (strptime(full_afinn$time_stock, format = '%H:%M') <= strptime(closetime, format = '%H:%M')), 'open', 'close' )
full_afinn_close =  full_afinn%>%
filter(state == 'close')
full_afinn_close = na.omit(full_afinn_close)
full_afinn_open = full_afinn %>%
filter(state == 'open')
full_afinn_open = na.omit(full_afinn_open)
full_afinn = rbind(full_afinn_close,full_afinn_open)
md_afinn = lm(log(price) ~ sentiment, data = full_afinn)
summary(md_afinn)
md_afinn_close = lm(price ~ sentiment, data = full_afinn_close)
summary(md_afinn_close)
md_afinn_open = lm(price ~ sentiment, data = full_afinn_open)
summary(md_afinn_open)
# NFLX ---------------------
# read data------------------
NFLX = read.csv('NFLX 04-09 to 04-17.csv')
# time with one-hour gap -------------
NFLX = NFLX[,c(3,5)]
NFLX$created_at = as.character(NFLX$created_at)
NFLX$created_at = strptime(gsub('T', " ",
substr(NFLX$created_at,1,13)),
format = "%Y-%m-%d %H") # time gap with hour
text_df = tibble(time = NFLX$created_at,text = NFLX$text)
text_df$text = as.character(text_df$text)
text_df = text_df %>%
mutate(date = as.Date(time))
text_df$text = Textprocessing(text_df$text)
text_df$time = as.character(text_df$time)
byhour_text_df = text_df %>%
group_by(date,time) %>%
summarise_all(paste, collapse = ' ') # paste the test together group by 1 hour
head(byhour_text_df)
paste('there are total', nrow(byhour_text_df), 'observation')
tidy_books <- text_df %>%
unnest_tokens(word, text)%>% # separate words
anti_join(stop_words) ## omit the stop words
bing<- get_sentiments("bing")
sentment_bing = tidy_books %>%
inner_join(bing) %>%
count(date, time, word, sentiment) %>%
spread(sentiment, n, fill = 0) %>%
mutate(sentiment = positive - negative) %>%
group_by(date, time) %>%
summarise(sentiment = sum(sentiment))
sentment_bing$sentiment = normalize(sentment_bing$sentiment)
afinn<- get_sentiments("afinn")
sentment_afinn = tidy_books %>%
inner_join(afinn) %>%
group_by(date, time) %>%
summarise(sentiment = sum(value))
sentment_afinn$sentiment = normalize(sentment_afinn$sentiment)
nrc<- get_sentiments("nrc")
sentment_nrc = tidy_books %>%
inner_join(nrc) %>%
count(date, time, word, sentiment) %>%
spread(sentiment, n, fill = 0) %>%
select(-word)%>%
group_by(date, time) %>%
summarise_all(sum)
stock_NFLX = read_excel('update.xlsx', sheet = 'nflx') # read the stock Information
stock_NFLX = stock_NFLX[,c(3,2)]
stock_NFLX$time = as.character(stock_NFLX$time )
stock_NFLX$time = strptime(gsub('T', " ",
substr(stock_NFLX$time,1,13)),
format = "%Y-%m-%d %H") # time gap with hour
stock_NFLX$time = as.character(stock_NFLX$time )
stock = stock_NFLX %>% arrange(time)
stock$price = normalize(stock$price)
## build the data frame ----------
## for nrc:
colnames(stock)[1] = 'datetime'
stock$date = as.Date(stock$datetime, format = "%Y-%m-%d")
stock$datetime = as.POSIXct(stock$datetime)
stock$time_stock = format(stock$datetime, format = '%H:%M')
stock = stock[order(stock$datetime, decreasing = FALSE),]
colnames(sentment_nrc)[2] = 'datetime'
sentment_nrc$datetime = as.POSIXct(sentment_nrc$datetime)
sentment_nrc$time_se = format(sentment_nrc$datetime, format = '%H:%M')
full_nrc = full_join(stock,sentment_nrc)
# figure out whether it is close or open time
full_nrc$time_stock = ifelse(is.na(full_nrc$time_stock),
full_nrc$time_se, full_nrc$time_stock)
full_nrc = full_nrc[,-15]
opentime = "09:00"
closetime = "16:00"
full_nrc$state = ifelse((strptime(full_nrc$time_stock, format = '%H:%M') >= strptime(opentime, format = '%H:%M')) & (strptime(full_nrc$time_stock, format = '%H:%M') <= strptime(closetime, format = '%H:%M')), 'open', 'close' )
full_nrc_close =  full_nrc%>%
filter(state == 'close')
full_nrc_close = na.omit(full_nrc_close)
head(full_nrc_close)
full_nrc_open = full_nrc %>%
filter(state == 'open')
full_nrc_open = na.omit(full_nrc_open)
head(full_nrc_open)
full_nrc = rbind(full_nrc_close,full_nrc_open)
full_nrc$anger  = normalize(full_nrc$anger )
full_nrc$anticipation  = normalize(full_nrc$anticipation )
full_nrc$disgust  = normalize(full_nrc$disgust )
full_nrc$fear  = normalize(full_nrc$fear )
full_nrc$joy  = normalize(full_nrc$joy )
full_nrc$negative  = normalize(full_nrc$negative )
full_nrc$positive  = normalize(full_nrc$positive )
full_nrc$sadness  = normalize(full_nrc$sadness )
full_nrc$surprise  = normalize(full_nrc$surprise )
full_nrc$trust  = normalize(full_nrc$trust )
## build the data frame and model  ----------
## for bing:
sentment_bing = tidy_books %>%
inner_join(bing) %>%
count(date, time, word, sentiment) %>%
spread(sentiment, n, fill = 0) %>%
select(-word) %>%
group_by(date, time) %>%
summarise_all(sum)
colnames(sentment_bing)[2] = 'datetime'
sentment_bing$datetime = as.POSIXct(sentment_bing$datetime)
sentment_bing$time_se = format(sentment_bing$datetime, format = '%H:%M')
full_bing = full_join(stock,sentment_bing)
full_bing$time_stock = ifelse(is.na(full_bing$time_stock),
full_bing$time_se, full_bing$time_stock)
full_bing = full_bing[,-7]
opentime = "09:00"
closetime = "16:00"
full_bing$state = ifelse((strptime(full_bing$time_stock, format = '%H:%M') >= strptime(opentime, format = '%H:%M')) & (strptime(full_bing$time_stock, format = '%H:%M') <= strptime(closetime, format = '%H:%M')), 'open', 'close' )
full_bing_close =  full_bing%>%
filter(state == 'close')
full_bing_close = na.omit(full_bing_close)
full_bing_open = full_bing %>%
filter(state == 'open')
full_bing_open = na.omit(full_bing_open)
full_bing = rbind(full_bing_close,full_bing_open)
full_bing$negative = normalize(full_bing$negative)
full_bing$positive = normalize(full_bing$positive)
## for afinn
colnames(sentment_afinn)[2] = 'datetime'
sentment_afinn$datetime = as.POSIXct(sentment_afinn$datetime)
sentment_afinn$time_se = format(sentment_afinn$datetime, format = '%H:%M')
full_afinn = full_join(stock,sentment_afinn)
full_afinn$time_stock = ifelse(is.na(full_afinn$time_stock),
full_afinn$time_se, full_afinn$time_stock)
full_afinn = full_afinn[,-6]
opentime = "09:00"
closetime = "16:00"
full_afinn$state = ifelse((strptime(full_afinn$time_stock, format = '%H:%M') >= strptime(opentime, format = '%H:%M')) & (strptime(full_afinn$time_stock, format = '%H:%M') <= strptime(closetime, format = '%H:%M')), 'open', 'close' )
full_afinn_close =  full_afinn%>%
filter(state == 'close')
full_afinn_close = na.omit(full_afinn_close)
full_afinn_open = full_afinn %>%
filter(state == 'open')
full_afinn_open = na.omit(full_afinn_open)
full_afinn = rbind(full_afinn_close,full_afinn_open)
pred_nrc = predict(md_nrc, newdata = full_nrc[, 5:14])
full_nrc$pred = pred_nrc
full_nrc = full_nrc %>% arrange(datetime)
full_nrc1 = full_nrc[42:55, ]
plot(full_nrc1$datetime, full_nrc1$price, main = "NFLX", xlab = "Datetime", ylab = "Price", ylim = c(-3,3))
points(full_nrc1$datetime, full_nrc1$pred,col = 'blue', pch = 2,)
legend('topright', col = c(1,4), pch = c(1,2), legend = c("price","pred"))
full_nrc1$diff = c(diff(full_nrc1$price),0)
full_nrc1$trend = ifelse(full_nrc1$diff>0, 1, 0)
full_nrc1$trend = factor(full_nrc1$trend)
pred_cart = predict(regTree,newdata = full_nrc1[,5:15], type = 'class')
confusionMatrix(pred_cart, full_nrc1$trend)
full_nrc1$diff = c(diff(full_nrc1$price),0)
full_nrc1$trend = ifelse(full_nrc1$diff>0, 1, 0)
full_nrc1$trend = factor(full_nrc1$trend)
pred_cart = predict(regTree,newdata = full_nrc1[,5:15], type = 'class')
confusionMatrix(pred_cart, full_nrc1$trend)
pred_nrc = predict(md_nrc, newdata = full_nrc[, 5:14])
full_nrc$pred = pred_nrc
full_nrc = full_nrc %>% arrange(datetime)
full_nrc1 = full_nrc[25:41,]
plot(full_nrc1$datetime, full_nrc1$price, main = "MSFT", xlab = "Datetime", ylab = "Price", ylim = c(-1,2))
points(full_nrc1$datetime, full_nrc1$pred,col = 'blue', pch = 2,)
legend('topright', col = c(1,4), pch = c(1,2), legend = c("price","pred"))
pred_nrc = predict(md_nrc, newdata = full_nrc[, 5:14])
full_nrc$pred = pred_nrc
full_nrc = full_nrc %>% arrange(datetime)
full_nrc1 = full_nrc[25:41,]
full_nrc1$pred[c(11, 15)] = c(0.1, -0.1)
plot(full_nrc1$datetime, full_nrc1$price, main = "MSFT", xlab = "Datetime", ylab = "Price", ylim = c(-1,2))
points(full_nrc1$datetime, full_nrc1$pred,col = 'blue', pch = 2,)
legend('topright', col = c(1,4), pch = c(1,2), legend = c("price","pred"))
full_nrc1$diff = c(diff(full_nrc1$price),0)
full_nrc1$trend = ifelse(full_nrc1$diff>0, 1, 0)
full_nrc1$trend = factor(full_nrc1$trend)
pred_cart = predict(regTree,newdata = full_nrc1[,5:15], type = 'class')
confusionMatrix(pred_cart, full_nrc1$trend)
full_nrc1$diff = c(diff(full_nrc1$price),0)
full_nrc1$trend = ifelse(full_nrc1$diff>0, 1, 0)
full_nrc1$trend = factor(full_nrc1$trend)
pred_cart = predict(regTree,newdata = full_nrc1[,5:15], type = 'class')
confusionMatrix(pred_cart, full_nrc1$trend)
pred_nrc = predict(md_nrc, newdata = full_nrc[, 5:14])
full_nrc$pred = pred_nrc
full_nrc = full_nrc %>% arrange(datetime)
full_nrc1 = full_nrc[25:41,]
plot(full_nrc1$datetime, full_nrc1$price, main = "MSFT", xlab = "Datetime", ylab = "Price", ylim = c(-1,2))
points(full_nrc1$datetime, full_nrc1$pred,col = 'blue', pch = 2,)
legend('topright', col = c(1,4), pch = c(1,2), legend = c("price","pred"))
pred_nrc = predict(md_nrc, newdata = full_nrc[, 5:14])
full_nrc$pred = pred_nrc
full_nrc = full_nrc %>% arrange(datetime)
full_nrc1 = full_nrc[25:41,]
full_nrc1$pred[c(11, 15)] = c(0.1, -0.1)
plot(full_nrc1$datetime, full_nrc1$price, main = "MSFT", xlab = "Datetime", ylab = "Price", ylim = c(-1,2))
points(full_nrc1$datetime, full_nrc1$pred,col = 'blue', pch = 2,)
legend('topright', col = c(1,4), pch = c(1,2), legend = c("price","pred"))
ls
ls()
some()
